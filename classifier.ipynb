{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.calibration import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.svm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     v1                                                 v2 Unnamed: 2  \\\n0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n1   ham                      Ok lar... Joking wif u oni...        NaN   \n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n3   ham  U dun say so early hor... U c already then say...        NaN   \n4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n\n  Unnamed: 3 Unnamed: 4  \n0        NaN        NaN  \n1        NaN        NaN  \n2        NaN        NaN  \n3        NaN        NaN  \n4        NaN        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.read_csv('data/sms-spam-collection-dataset/spam.csv', encoding = \"latin-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing column 2, 3 and 4 as they have no useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                 SMS  label\n0  Go until jurong point, crazy.. Available only ...      0\n1                      Ok lar... Joking wif u oni...      0\n2  Free entry in 2 a wkly comp to win FA Cup fina...      1\n3  U dun say so early hor... U c already then say...      0\n4  Nah I don't think he goes to usf, he lives aro...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SMS</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
    "df['SMS'] = df['v2']\n",
    "df['label'] = df['v1'].map({'ham': 0, 'spam': 1})\n",
    "df.drop(['v1', 'v2'], axis=1, inplace=True)\n",
    "train_data = df[:4400]\n",
    "test_data = df[4400:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform(classifiers, vectorizers, train_data, test_data):\n",
    "    max_score = 0\n",
    "    max_name = 0\n",
    "    for classifier in classifiers:\n",
    "        for vectorizer in vectorizers:\n",
    "        \n",
    "            # train\n",
    "            vectorize_text = vectorizer.fit_transform(train_data.SMS)\n",
    "            classifier.fit(vectorize_text, train_data.label)\n",
    "\n",
    "            # score\n",
    "            vectorize_text = vectorizer.transform(test_data.SMS)\n",
    "            score = classifier.score(vectorize_text, test_data.label)\n",
    "            name = classifier.__class__.__name__ + ' with ' + vectorizer.__class__.__name__ \n",
    "            print(name, score)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_name = name\n",
    "    print ('===========================================')\n",
    "    print ('===========================================')\n",
    "    print (max_name, max_score)\n",
    "    print ('===========================================')\n",
    "    print ('===========================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of various classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "        BernoulliNB(),\n",
    "        RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        ExtraTreesClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        CalibratedClassifierCV(),\n",
    "        DummyClassifier(),\n",
    "        PassiveAggressiveClassifier(),\n",
    "        RidgeClassifier(),\n",
    "        RidgeClassifierCV(),\n",
    "        SGDClassifier(),\n",
    "        OneVsRestClassifier(SVC(kernel='linear')),\n",
    "        OneVsRestClassifier(LogisticRegression()),\n",
    "        KNeighborsClassifier()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of various vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = [\n",
    "        CountVectorizer(),\n",
    "        TfidfVectorizer(),\n",
    "        HashingVectorizer()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing classification and save results to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "BernoulliNB with CountVectorizer 0.9778156996587031\nBernoulliNB with TfidfVectorizer 0.9778156996587031\nBernoulliNB with HashingVectorizer 0.8728668941979523\nRandomForestClassifier with CountVectorizer 0.9795221843003413\nRandomForestClassifier with TfidfVectorizer 0.9744027303754266\nRandomForestClassifier with HashingVectorizer 0.9684300341296929\nAdaBoostClassifier with CountVectorizer 0.9718430034129693\nAdaBoostClassifier with TfidfVectorizer 0.9692832764505119\nAdaBoostClassifier with HashingVectorizer 0.9735494880546075\nBaggingClassifier with CountVectorizer 0.9701365187713311\nBaggingClassifier with TfidfVectorizer 0.9692832764505119\nBaggingClassifier with HashingVectorizer 0.9692832764505119\nExtraTreesClassifier with CountVectorizer 0.9812286689419796\nExtraTreesClassifier with TfidfVectorizer 0.9786689419795221\nExtraTreesClassifier with HashingVectorizer 0.9667235494880546\nGradientBoostingClassifier with CountVectorizer 0.9692832764505119\nGradientBoostingClassifier with TfidfVectorizer 0.9667235494880546\nGradientBoostingClassifier with HashingVectorizer 0.9726962457337884\nDecisionTreeClassifier with CountVectorizer 0.96160409556314\nDecisionTreeClassifier with TfidfVectorizer 0.96160409556314\nDecisionTreeClassifier with HashingVectorizer 0.9581911262798635\nCalibratedClassifierCV with CountVectorizer 0.9863481228668942\nCalibratedClassifierCV with TfidfVectorizer 0.9863481228668942\nCalibratedClassifierCV with HashingVectorizer 0.9820819112627986\nDummyClassifier with CountVectorizer 0.7679180887372014\nDummyClassifier with TfidfVectorizer 0.7849829351535836\nDummyClassifier with HashingVectorizer 0.7687713310580204\nPassiveAggressiveClassifier with CountVectorizer 0.9829351535836177\nPassiveAggressiveClassifier with TfidfVectorizer 0.9863481228668942\nPassiveAggressiveClassifier with HashingVectorizer 0.9837883959044369\nRidgeClassifier with CountVectorizer 0.9812286689419796\nRidgeClassifier with TfidfVectorizer 0.9829351535836177\nRidgeClassifier with HashingVectorizer 0.9820819112627986\nRidgeClassifierCV with CountVectorizer 0.9829351535836177\nRidgeClassifierCV with TfidfVectorizer 0.984641638225256\nRidgeClassifierCV with HashingVectorizer 0.9803754266211604\nSGDClassifier with CountVectorizer 0.9795221843003413\nSGDClassifier with TfidfVectorizer 0.9863481228668942\nSGDClassifier with HashingVectorizer 0.984641638225256\nOneVsRestClassifier with CountVectorizer 0.9863481228668942\nOneVsRestClassifier with TfidfVectorizer 0.9880546075085325\nOneVsRestClassifier with HashingVectorizer 0.9829351535836177\nOneVsRestClassifier with CountVectorizer 0.9837883959044369\nOneVsRestClassifier with TfidfVectorizer 0.9752559726962458\nOneVsRestClassifier with HashingVectorizer 0.9684300341296929\nKNeighborsClassifier with CountVectorizer 0.924061433447099\nKNeighborsClassifier with TfidfVectorizer 0.962457337883959\nKNeighborsClassifier with HashingVectorizer 0.9607508532423208\n===========================================\n===========================================\nSGDClassifier with HashingVectorizer 0.984641638225256\n===========================================\n===========================================\n"
    }
   ],
   "source": [
    "perform(\n",
    "    classifiers,\n",
    "    vectorizers,\n",
    "    train_data,\n",
    "    test_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OneVsRestClassifier(estimator=SVC(kernel='linear', probability=True))"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# train the classifier with best accuracy\n",
    "Classifier = OneVsRestClassifier(SVC(kernel='linear', probability = True))\n",
    "Vectorizer = TfidfVectorizer()\n",
    "vectorize_text = Vectorizer.fit_transform(train_data.SMS)\n",
    "Classifier.fit(vectorize_text, train_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMS = ' won a 1 week FREE membership in our $100,000 Prize Jackpot! Txt the word: C'\n",
    "vectorize_message = Vectorizer.transform([SMS])\n",
    "predict = Classifier.predict(vectorize_message)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "spam\n"
    }
   ],
   "source": [
    "if predict == 0:\n",
    "    print ('ham')\n",
    "else:\n",
    "    print ('spam')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}